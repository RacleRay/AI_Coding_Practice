{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要使用的工具\n",
    "- face_recognition\n",
    "- cv2\n",
    "- PIL\n",
    "- tensorflow\n",
    "- keras\n",
    "- gc \n",
    "- glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、截取人脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(object):\n",
    "\n",
    "    def __init__(self, scale_size=139):\n",
    "        self.img_cant = []  # 失效图片路径\n",
    "        self.scale_size = scale_size  # 统一尺寸\n",
    "\n",
    "    @staticmethod\n",
    "    def show_face(path):\n",
    "        \"test\"\n",
    "        image = face_recognition.load_image_file(path)\n",
    "        face_locations = face_recognition.face_locations(image)  # list\n",
    "        if len(face_locations) == 0:\n",
    "            return -1\n",
    "        for k, i in enumerate(face_locations):\n",
    "            (a, b, c, d) = i\n",
    "            image_spilt = image[a:c, d:b, :]\n",
    "            cv2.imshow(\"img_{}\".format(k), image_spilt)\n",
    "            return 1\n",
    "\n",
    "    def split_face(self, in_path, out_path, use_cnn):\n",
    "        \"main process\"\n",
    "        image = face_recognition.load_image_file(in_path)\n",
    "        # 图片尺寸限制\n",
    "        if max(image.shape) > 2000:\n",
    "            if image.shape[0] > image.shape[1]:\n",
    "                image = cv2.resize(\n",
    "                    image, (2000, int(2000 * image.shape[1] / image.shape[0])))\n",
    "            else:\n",
    "                image = cv2.resize(\n",
    "                    image, (int(2000 * image.shape[0] / image.shape[1]), 2000))\n",
    "\n",
    "        if not use_cnn:\n",
    "            face_locations = face_recognition.face_locations(image)\n",
    "        else:\n",
    "            face_locations = face_recognition.face_locations(\n",
    "                image, number_of_times_to_upsample=1, model=\"cnn\")\n",
    "\n",
    "        img_name = os.path.basename(in_path)\n",
    "        if len(face_locations) == 0:  # 失效部分\n",
    "            self.img_cant.append(img_name)\n",
    "            print(img_name)\n",
    "            return\n",
    "\n",
    "        for k, i in enumerate(face_locations):  # 截取识别出的人脸\n",
    "            (a, b, c, d) = i\n",
    "            image_spilt = image[a:c, d:b, :]\n",
    "            image_spilt = self.scale_img(image_spilt)\n",
    "            img = Image.fromarray(image_spilt)\n",
    "            img.save(out_path + \"/{}_{}.png\".format(img_name, k))\n",
    "            print(\"success\")\n",
    "\n",
    "    def scale_img(self, img):\n",
    "        \"等比缩放，截取\"\n",
    "        h, w = img.shape[:2]\n",
    "        if h > w:\n",
    "            new_h, new_w = self.scale_size * h / w, self.scale_size\n",
    "        else:\n",
    "            new_h, new_w = self.scale_size, self.scale_size * w / h\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "        # 截取\n",
    "        if h == w:\n",
    "            return img\n",
    "        elif h < w:\n",
    "            top = 0\n",
    "            left = np.random.randint(0, new_w - self.scale_size)\n",
    "        elif h > w:\n",
    "            top = np.random.randint(0, new_h - self.scale_size)\n",
    "            left = 0\n",
    "\n",
    "        img = img[top:top + self.scale_size, left:left + self.scale_size]\n",
    "        return img\n",
    "\n",
    "    def preprocess(self, in_path, out_path, use_cnn=False):\n",
    "        path_lst = glob.glob(in_path + \"/*.jpg\")\n",
    "        for index, path in enumerate(path_lst):\n",
    "            if index % 20 == 0:\n",
    "                gc.collect()\n",
    "            print(path)\n",
    "            self.split_face(path, out_path, use_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preprocess\n",
    "dir_lst = [\"data/{}\".format(i) for i in range(5)]\n",
    "\n",
    "train_ins = Preprocess()\n",
    "\n",
    "for in_path in dir_lst:\n",
    "    out_path = os.path.basename(in_path) + \"_face\"\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "    train_ins.preprocess(in_path, out_path, use_cnn=False)\n",
    "    with open(\"train_face_cant_{}.pkl\".format(os.path.basename(in_path)),\n",
    "              \"wb\") as f:\n",
    "        pickle.dump(train_ins.img_cant, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2tfrecord(image_list, label_list, filename):\n",
    "    \"\"\"\n",
    "    image_list:image path list\n",
    "    label_list:label list\n",
    "    \"\"\"\n",
    "    length = len(image_list)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for i in range(length):\n",
    "        if i % 100 == 0:\n",
    "            ratio = round(i / float(length), 4)\n",
    "            sys.stdout.write(\"ratio:{}\\r\".format(ratio))\n",
    "            sys.stdout.flush()\n",
    "        image = Image.open(image_list[i])\n",
    "        if \"png\" in image_list[i][-4:]:\n",
    "            if image.mode == \"RGB\":\n",
    "                r, g, b = image.split()\n",
    "                image = Image.merge(\"RGB\", (r, g, b))\n",
    "            elif image.mode == \"L\":  # 灰度\n",
    "                pass\n",
    "            else:  # 透明通道处理\n",
    "                r, g, b, a = image.split()\n",
    "                image = Image.merge(\"RGB\", (r, g, b))\n",
    "        image = image.resize((139, 139))\n",
    "\n",
    "        image_bytes = image.tobytes()\n",
    "        features = {}\n",
    "        features[\"image\"] = tf.train.Feature(bytes_list=tf.train.BytesList(\n",
    "            value=[image_bytes]))\n",
    "        features[\"label\"] = tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "            value=[int(label_list[i])]))\n",
    "        tf_features = tf.train.Features(feature=features)\n",
    "        tf_example = tf.train.Example(features=tf_features)\n",
    "        tf_serialized = tf_example.SerializeToString()\n",
    "        writer.write(tf_serialized)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "random_ratio = 0.05\n",
    "sum_number = 0\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    image_list = np.array(\n",
    "        glob.glob(os.path.join(cwd, \"{}_face\".format(i)) + \"/*.png\"))\n",
    "\n",
    "    test_choice = np.random.choice(range(len(image_list)),\n",
    "                                   size=int(len(image_list) * random_ratio),\n",
    "                                   replace=False)\n",
    "    train_choice = list(set(range(len(image_list))).difference(test_choice))\n",
    "\n",
    "    image_list_train = image_list[train_choice]\n",
    "    image_list_test = image_list[test_choice]\n",
    "    label_list = np.zeros(len(image_list)) + i\n",
    "\n",
    "    image2tfrecord(\n",
    "        image_list_train,\n",
    "        np.zeros(len(image_list_train)) + i,\n",
    "        \"face_train_{}.tfrecords\".format(i),\n",
    "    )\n",
    "    image2tfrecord(\n",
    "        image_list_test,\n",
    "        np.zeros(len(image_list_test)) + i,\n",
    "        \"face_test_{}.tfrecords\".format(i),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "def pre_process(\n",
    "    images,\n",
    "    random_flip_up_down=False,\n",
    "    random_flip_left_right=False,\n",
    "    random_brightness=True,\n",
    "    random_contrast=True,\n",
    "    random_saturation=False,\n",
    "    random_hue=False,\n",
    "):\n",
    "    if random_flip_up_down:\n",
    "        images = tf.image.random_flip_up_down(images)\n",
    "    if random_flip_left_right:\n",
    "        images = tf.image.random_flip_left_right(images)\n",
    "    if random_brightness:\n",
    "        images = tf.image.random_brightness(images, max_delta=0.2)\n",
    "    if random_contrast:\n",
    "        images = tf.image.random_contrast(images, 0.9, 1.1)\n",
    "    if random_saturation:\n",
    "        images = tf.image.random_saturation(images, 0.3, 0.5)\n",
    "    if random_hue:\n",
    "        images = tf.image.random_hue(images, 0.2)\n",
    "    new_size = tf.constant([28, 28], dtype=tf.int32)\n",
    "    images = tf.image.resize_images(images, new_size)\n",
    "    return images\n",
    "\n",
    "\n",
    "# 解析函数\n",
    "def pares_tf(example_proto):\n",
    "    dics = {}\n",
    "    dics[\"label\"] = tf.FixedLenFeature((), dtype=tf.int64, default_value=0)\n",
    "    dics[\"image\"] = tf.FixedLenFeature((), dtype=tf.string, default_value=\"\")\n",
    "\n",
    "    parsed_example = tf.parse_single_example(serialized=example_proto,\n",
    "                                             features=dics)\n",
    "    image = tf.decode_raw(parsed_example[\"image\"], out_type=tf.uint8)\n",
    "    # image=tf.image.decode_jpeg(parsed_example['image'], channels=1)\n",
    "\n",
    "    # 增强\n",
    "    image = tf.reshape(image, (139, 139, 3))\n",
    "    image = pre_process(image)\n",
    "    image = tf.cast(image, tf.float32) / 255\n",
    "    # 标签的操作\n",
    "    label = parsed_example[\"label\"]\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = tf.one_hot(label, depth=5, on_value=1.0, off_value=0.0)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# dataset\n",
    "def dataset(filenames, batch_size, epochs):\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "    new_dataset = dataset.map(pares_tf)\n",
    "    shuffle_dataset = new_dataset.shuffle(buffer_size=(100000))\n",
    "    batch_dataset = shuffle_dataset.batch(batch_size).repeat(epochs)\n",
    "    batch_dataset = batch_dataset.prefetch(1)\n",
    "    iterator = batch_dataset.make_one_shot_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    return next_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/prefetch.png\" style=\"zoom:30%\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# filenames = [\"data/face_train_{}.tfrecords\".format(i) for i in range(5)]\n",
    "# next_batch = dataset(filenames, batch_size=5, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "total_sum = 0\n",
    "epoch = 0\n",
    "random_ratio = 0.05\n",
    "\n",
    "filenames_train = [\"data/face_train_{}.tfrecords\".format(i) for i in range(5)]\n",
    "filenames_test = [\"data/face_test_{}.tfrecords\".format(i) for i in range(5)]\n",
    "\n",
    "test_num = sum([\n",
    "    int(len(glob.glob(\"./face/{}_face/*.png\".format(i))) * random_ratio)\n",
    "    for i in range(5)\n",
    "])\n",
    "train_num = (\n",
    "    sum([len(glob.glob(\"./face/{}_face/*.png\".format(i))) for i in range(5)]) -\n",
    "    test_num)\n",
    "\n",
    "train_set = dataset(filenames_train, batch_size=batch_size, epochs=epochs)\n",
    "next_element_trest = dataset(filenames_test, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.float32, shape=(None, 139, 139, 3))\n",
    "input_label = tf.placeholder(tf.float32, shape=(None, 5))\n",
    "# 139\n",
    "hidden = tf.keras.layers.Conv2D(filters=16,\n",
    "                                kernel_size=3,\n",
    "                                strides=1,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")(input_data)\n",
    "# 137\n",
    "hidden = tf.keras.layers.MaxPool2D(pool_size=2)(hidden)\n",
    "# 68\n",
    "hidden = tf.keras.layers.Conv2D(filters=32,\n",
    "                                kernel_size=3,\n",
    "                                strides=2,\n",
    "                                padding=\"same\",\n",
    "                                activation=\"relu\")(hidden)\n",
    "# 34\n",
    "hidden = tf.keras.layers.MaxPool2D(pool_size=2)(hidden)\n",
    "# 17\n",
    "hidden = tf.keras.layers.Conv2D(filters=64,\n",
    "                                kernel_size=3,\n",
    "                                strides=2,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")(hidden)\n",
    "# 8\n",
    "hidden = tf.keras.layers.MaxPool2D(pool_size=2)(hidden)\n",
    "# 4\n",
    "hidden = tf.keras.layers.Conv2D(filters=128,\n",
    "                                kernel_size=3,\n",
    "                                strides=2,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")(hidden)\n",
    "# 1\n",
    "hidden = tf.layers.Flatten()(hidden)\n",
    "\n",
    "output = tf.keras.layers.Dense(5, activation=\"softmax\")(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "loss = tf.reduce_mean(\n",
    "    tf.keras.losses.categorical_crossentropy(input_label, output))\n",
    "\n",
    "# 优化器\n",
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss)\n",
    "\n",
    "# 测试评估\n",
    "acc = tf.reduce_mean(tf.keras.metrics.categorical_accuracy(input_label, output))\n",
    "# correct_pred = tf.equal(tf.argmax(input_label,axis=1),tf.argmax(output,axis=1))\n",
    "# acc = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "tf.add_to_collection(\"my_op\", input_data)\n",
    "tf.add_to_collection(\"my_op\", output)\n",
    "tf.add_to_collection(\"my_op\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run([init])\n",
    "    while epoch < epochs:\n",
    "        data, label = sess.run([train_set[0], train_set[1]])\n",
    "\n",
    "        total_sum += batch_size\n",
    "        _, loss_val = sess.run([train_op, loss],\n",
    "                               feed_dict={\n",
    "                                   input_data: data,\n",
    "                                   input_label: label\n",
    "                               })\n",
    "\n",
    "        if total_sum % 20 == 0:\n",
    "            sys.stdout.write(\"epoch:{},index:{}\\\\{},loss:{:.4f}\\r\".format(\n",
    "                epoch, total_sum % train_num, train_num, loss_val))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if total_sum // train_num > epoch:\n",
    "            epoch = total_sum // train_num\n",
    "            loss_val = sess.run([loss],\n",
    "                                feed_dict={\n",
    "                                    input_data: data,\n",
    "                                    input_label: label\n",
    "                                })\n",
    "\n",
    "            test_set = dataset(filenames_test, batch_size=batch_size, epochs=1)\n",
    "            total_test_sum = 0\n",
    "            acc_test_lst = []\n",
    "            while total_test_sum < test_num:\n",
    "                total_test_sum += batch_size\n",
    "                test_data, test_label = sess.run([test_set[0], test_set[1]])\n",
    "                acc_test = sess.run([acc],\n",
    "                                    feed_dict={\n",
    "                                        input_data: test_data,\n",
    "                                        input_label: test_label\n",
    "                                    })\n",
    "                acc_test_lst.append(acc_test[0])\n",
    "\n",
    "            acc_val = sum(acc_test_lst) / len(acc_test_lst)\n",
    "            saver.save(sess, save_path=\"./model/my_model.ckpt\")\n",
    "            print(\"epoch:{},train_loss:{:.4f},test_acc:{:.4f}\".format(\n",
    "                epoch, loss_val[0], acc_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit nlp",
   "language": "python",
   "name": "python36864bit023718609e434315a7782a7404fb6072"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
