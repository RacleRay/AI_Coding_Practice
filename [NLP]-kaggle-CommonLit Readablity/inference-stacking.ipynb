{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-02T06:59:25.181980Z","iopub.execute_input":"2021-08-02T06:59:25.182359Z","iopub.status.idle":"2021-08-02T06:59:25.290371Z","shell.execute_reply.started":"2021-08-02T06:59:25.182277Z","shell.execute_reply":"2021-08-02T06:59:25.289515Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/comlitrobertalargescript/config.json\n/kaggle/input/comlitrobertalargescript/merges.txt\n/kaggle/input/comlitrobertalargescript/tokenizer.json\n/kaggle/input/comlitrobertalargescript/vocab.json\n/kaggle/input/comlitrobertalargescript/tokenizer_config.json\n/kaggle/input/comlitrobertalargescript/pytorch_model.bin\n/kaggle/input/comlitrobertalargescript/special_tokens_map.json\n/kaggle/input/tokenizer/roberta_tk.pt\n/kaggle/input/tokenizer/bert_cased_tk.pt\n/kaggle/input/commonlitreadabilityprize/sample_submission.csv\n/kaggle/input/commonlitreadabilityprize/train.csv\n/kaggle/input/commonlitreadabilityprize/test.csv\n/kaggle/input/comlitmldata/embed4.bin\n/kaggle/input/comlitmldata/mldata.csv\n/kaggle/input/comlitmldata/embed3.bin\n/kaggle/input/comlitmldata/embed2.bin\n/kaggle/input/comlitmldata/embed1.bin\n/kaggle/input/cmlit-fold/new_kfold.csv\n/kaggle/input/cmlit-fold/train_data.csv\n/kaggle/input/comlitrobertabasescript/pre_config.json.backup\n/kaggle/input/comlitrobertabasescript/config.json\n/kaggle/input/comlitrobertabasescript/merges.txt\n/kaggle/input/comlitrobertabasescript/tokenizer.json\n/kaggle/input/comlitrobertabasescript/vocab.json\n/kaggle/input/comlitrobertabasescript/tokenizer_config.json\n/kaggle/input/comlitrobertabasescript/pytorch_model.bin\n/kaggle/input/comlitrobertabasescript/special_tokens_map.json\n/kaggle/input/largeattnlit/config.json\n/kaggle/input/largeattnlit/merges.txt\n/kaggle/input/largeattnlit/model_0.bin\n/kaggle/input/largeattnlit/model_1.bin\n/kaggle/input/largeattnlit/tokenizer.json\n/kaggle/input/largeattnlit/vocab.json\n/kaggle/input/largeattnlit/tokenizer_config.json\n/kaggle/input/largeattnlit/model_3.bin\n/kaggle/input/largeattnlit/model_2.bin\n/kaggle/input/largeattnlit/model_4.bin\n/kaggle/input/largeattnlit/special_tokens_map.json\n/kaggle/input/textstat-local/__notebook_source__.ipynb\n/kaggle/input/textstat-local/textstat/Pyphen-0.10.0-py3-none-any.whl\n/kaggle/input/textstat-local/textstat/textstat-0.7.1-py3-none-any.whl\n/kaggle/input/textstat-local/packages/__notebook_source__.ipynb\n/kaggle/input/textstat-local/packages/textstat/Pyphen-0.10.0-py3-none-any.whl\n/kaggle/input/textstat-local/packages/textstat/textstat-0.7.1-py3-none-any.whl\n/kaggle/input/comlitothers/model_5.bin\n/kaggle/input/comlitothers/model_1.bin\n/kaggle/input/comlitothers/model_3.bin\n/kaggle/input/comlitothers/model_2.bin\n/kaggle/input/comlitothers/model_4.bin\n/kaggle/input/attlargereinit/config.json\n/kaggle/input/attlargereinit/merges.txt\n/kaggle/input/attlargereinit/model_0.bin\n/kaggle/input/attlargereinit/model_1.bin\n/kaggle/input/attlargereinit/tokenizer.json\n/kaggle/input/attlargereinit/vocab.json\n/kaggle/input/attlargereinit/tokenizer_config.json\n/kaggle/input/attlargereinit/model_3.bin\n/kaggle/input/attlargereinit/model_2.bin\n/kaggle/input/attlargereinit/model_4.bin\n/kaggle/input/attlargereinit/special_tokens_map.json\n/kaggle/input/meanlargereinit/config.json\n/kaggle/input/meanlargereinit/merges.txt\n/kaggle/input/meanlargereinit/model_0.bin\n/kaggle/input/meanlargereinit/model_1.bin\n/kaggle/input/meanlargereinit/tokenizer.json\n/kaggle/input/meanlargereinit/vocab.json\n/kaggle/input/meanlargereinit/tokenizer_config.json\n/kaggle/input/meanlargereinit/model_3.bin\n/kaggle/input/meanlargereinit/model_2.bin\n/kaggle/input/meanlargereinit/model_4.bin\n/kaggle/input/meanlargereinit/special_tokens_map.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom joblib import dump, load\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import RandomSampler, SequentialSampler, Sampler\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig\n\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom time import time\nfrom colorama import Fore, Back, Style\n\nr_ = Fore.RED\nb_ = Fore.BLUE\ng_ = Fore.GREEN\ny_ = Fore.YELLOW\nw_ = Fore.WHITE\nbb_ = Back.BLACK\nby_ = Back.YELLOW\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:25.293533Z","iopub.execute_input":"2021-08-02T06:59:25.293848Z","iopub.status.idle":"2021-08-02T06:59:32.693963Z","shell.execute_reply.started":"2021-08-02T06:59:25.293819Z","shell.execute_reply":"2021-08-02T06:59:32.693084Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Global config","metadata":{}},{"cell_type":"code","source":"class Config:\n    epochs = 3\n    batch_size = 16\n    test_batch = 32\n    \n    device = 'cuda'\n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    weight_decay = 0.01\n    \n    num_labels = 1","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.695620Z","iopub.execute_input":"2021-08-02T06:59:32.695945Z","iopub.status.idle":"2021-08-02T06:59:32.703963Z","shell.execute_reply.started":"2021-08-02T06:59:32.695905Z","shell.execute_reply":"2021-08-02T06:59:32.703023Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class RoBERTaDataset(Dataset):\n    def __init__(self, df, tokenizer, for_test=False):\n        super().__init__()\n        self.text = df['excerpt'].values\n        self.for_test = for_test\n        if not for_test:\n            self.target = df['target'].values\n        self.max_len = Config.max_len\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = self.text[index]\n        text = ' '.join(text.split())\n        inputs = self.tokenizer.encode_plus(text,\n                                            None,\n                                            truncation=True,\n                                            add_special_tokens=True,\n                                            max_length=self.max_len,\n                                            padding='max_length')\n\n        if not self.for_test:\n            return {\n                'input_ids':\n                    torch.tensor(inputs['input_ids'], dtype=torch.long),\n                'attention_mask':\n                    torch.tensor(inputs['attention_mask'], dtype=torch.long),\n                'label':\n                    torch.tensor(self.target[index], dtype=torch.float)\n            }\n        else:\n            return {\n                'input_ids':\n                    torch.tensor(inputs['input_ids'], dtype=torch.long),\n                'attention_mask':\n                    torch.tensor(inputs['attention_mask'], dtype=torch.long)\n            }","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.705986Z","iopub.execute_input":"2021-08-02T06:59:32.706348Z","iopub.status.idle":"2021-08-02T06:59:32.719183Z","shell.execute_reply.started":"2021-08-02T06:59:32.706308Z","shell.execute_reply":"2021-08-02T06:59:32.718166Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Attn 1","metadata":{}},{"cell_type":"code","source":"# CLRPModel: 467    BaseOne: 474  Base 2: 475     \nclass AttnOneConifg:\n    model_name = 'roberta-base'\n    pretrained_model_path = '/kaggle/input/comlitrobertabasescript/'\n    \n    epochs = 3\n    batch_size = 16\n    test_batch = 32\n    \n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    weight_decay = 0.01","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.720793Z","iopub.execute_input":"2021-08-02T06:59:32.721065Z","iopub.status.idle":"2021-08-02T06:59:32.729686Z","shell.execute_reply.started":"2021-08-02T06:59:32.721024Z","shell.execute_reply":"2021-08-02T06:59:32.728762Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Using Model\n# Base Model One         Base Model Two\nclass AttentionHead_Ori(nn.Module):\n    def __init__(self, h_size, hidden_dim=512):\n        super().__init__()\n        self.W = nn.Linear(h_size, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n\nclass CLRPModel(nn.Module):\n    def __init__(self):\n        super(CLRPModel, self).__init__()\n        config = AutoConfig.from_pretrained(AttnOneConifg.pretrained_model_path)\n        config.update({\"output_hidden_states\":True,\n                        \"hidden_dropout_prob\": 0.0,\n                        \"layer_norm_eps\": 1e-7})\n        self.h_size = config.hidden_size\n        self.transformer = AutoModel.from_pretrained(AttnOneConifg.pretrained_model_path, config=config)\n        self.head = AttentionHead_Ori(self.h_size)\n        self.linear = nn.Linear(self.h_size, 1)\n\n    def forward(self, input_ids, attention_mask):\n        transformer_out = self.transformer(input_ids, attention_mask)\n        context = self.head(transformer_out.last_hidden_state)\n        x = self.linear(context)\n        return x, context","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.731759Z","iopub.execute_input":"2021-08-02T06:59:32.732054Z","iopub.status.idle":"2021-08-02T06:59:32.746534Z","shell.execute_reply.started":"2021-08-02T06:59:32.732027Z","shell.execute_reply":"2021-08-02T06:59:32.745645Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 467\nclass LitModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        config = AutoConfig.from_pretrained(AttnOneConifg.pretrained_model_path)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7})                       \n        \n        self.roberta = AutoModel.from_pretrained(AttnOneConifg.pretrained_model_path, config=config)  \n        self.attention = nn.Sequential(            \n            nn.Linear(768, 512),            \n            nn.Tanh(),                       \n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )        \n        self.regressor = nn.Sequential(nn.Linear(768, 1))\n        \n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids, attention_mask)        \n        last_hidden_states = roberta_output.hidden_states[-1]\n        \n        weights = self.attention(last_hidden_states)\n        context_vector = torch.sum(weights * last_hidden_states, dim=1)        \n        \n        return self.regressor(context_vector), context_vector","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.750020Z","iopub.execute_input":"2021-08-02T06:59:32.750334Z","iopub.status.idle":"2021-08-02T06:59:32.761315Z","shell.execute_reply.started":"2021-08-02T06:59:32.750305Z","shell.execute_reply":"2021-08-02T06:59:32.760293Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model MeanPooling Large and MeanEmbedding","metadata":{}},{"cell_type":"markdown","source":"MeanEmbedding完全可以和Model MeanPooling Large合在一起\n\n- MeanEmbedding V1 + SVM 473","metadata":{}},{"cell_type":"code","source":"# Mean Model\nclass MeanLargeConfig:\n    model_name = 'roberta-large'\n    pretrained_model_path = '../input/comlitrobertalargescript'\n    \n    epochs = 3\n    batch_size = 16\n    test_batch = 32\n    \n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    weight_decay = 0.01\n    \n    head_hidden = 512\n    \n    use_multi_sample_dropout = True # this model didn`t help","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.764440Z","iopub.execute_input":"2021-08-02T06:59:32.765849Z","iopub.status.idle":"2021-08-02T06:59:32.773424Z","shell.execute_reply.started":"2021-08-02T06:59:32.765809Z","shell.execute_reply":"2021-08-02T06:59:32.772630Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# V1 large :  inference model  同时输出 logits 和 pool_out embedding，可以选择 如何取舍两个输出。\n#             MeanEmbedding V1 + SVM 473\n#                    logits          472\nclass MeanPooling(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        \n    def forward(self, hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\n    \nclass MeanModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(MeanLargeConfig.pretrained_model_path)\n        self.config.update({\"output_hidden_states\": True,\n                            \"hidden_dropout_prob\": 0.0,\n                            \"attention_probs_dropout_prob\": 0.1,\n                            \"layer_norm_eps\": 1e-7}) \n        self.roberta = AutoModel.from_pretrained(MeanLargeConfig.pretrained_model_path,\n                                                 config=self.config)\n        self.layer_norm = nn.LayerNorm(self.config.hidden_size, eps=1e-7)\n        self.pooler = MeanPooling(self.config.hidden_size)\n\n        self.low_dropout = nn.Dropout(0.1)\n        self.dropout = nn.Dropout(p=0.5)\n        self.regressor = nn.Linear(self.config.hidden_size, 1)\n\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n        \n        ## MeanPooling\n        hidden_states = outputs[0]\n        pool_out = self.pooler(hidden_states, attention_mask)\n        # pool_out = self.low_dropout(pool_out)\n        \n        # didn`t help\n        logits = torch.mean(torch.stack([self.regressor(self.dropout(pool_out)) for _ in range(5)], dim=0), dim=0)\n\n        return (logits, pool_out)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.777283Z","iopub.execute_input":"2021-08-02T06:59:32.777618Z","iopub.status.idle":"2021-08-02T06:59:32.791076Z","shell.execute_reply.started":"2021-08-02T06:59:32.777590Z","shell.execute_reply":"2021-08-02T06:59:32.790250Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Attn v2","metadata":{}},{"cell_type":"code","source":"class AttConfig1:\n    model_name = 'roberta-large'\n    pretrained_model_path = '../input/comlitrobertalargescript'\n    \n    output_hidden_states = True\n    epochs = 3\n    num_labels = 1\n    \n    device = 'cuda'\n    \n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    weight_decay = 0.01\n    head_hidden = 512\n    \n    warmup_steps = 50","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.794126Z","iopub.execute_input":"2021-08-02T06:59:32.794344Z","iopub.status.idle":"2021-08-02T06:59:32.801428Z","shell.execute_reply.started":"2021-08-02T06:59:32.794324Z","shell.execute_reply":"2021-08-02T06:59:32.800649Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, hidden_state, attention_mask):\n        att = torch.tanh(self.W(hidden_state))\n        score = self.V(att)\n\n        mask_expanded = attention_mask.unsqueeze(-1)\n        score[~mask_expanded] = -1e9\n\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * hidden_state\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n    \n    \nclass AttModel(nn.Module):\n    def __init__(self, config, attn_type='tradition'):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(config.pretrained_model_path)\n        self.config.update({\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": 0.0,\n                \"attention_probs_dropout_prob\": 0.1,\n                \"layer_norm_eps\": 1e-7\n                }) \n        self.roberta = AutoModel.from_pretrained(config.pretrained_model_path,\n                                                 config=self.config)\n        self.head = AttentionHead(self.config.hidden_size, config.head_hidden)\n        \n        self.layer_norm = nn.LayerNorm(self.config.hidden_size, eps=1e-5)\n        self.regressor = nn.Linear(self.config.hidden_size, config.num_labels)\n        \n        self.dropout = nn.Dropout(p=0.1)\n        self.m_dropout = nn.Dropout(p=0.5)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n        hidden_states = outputs[2][-1]\n\n        x = self.head(hidden_states, attention_mask)\n        logits = self.regressor(x)\n\n        return logits, x","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.802916Z","iopub.execute_input":"2021-08-02T06:59:32.803334Z","iopub.status.idle":"2021-08-02T06:59:32.818802Z","shell.execute_reply.started":"2021-08-02T06:59:32.803296Z","shell.execute_reply":"2021-08-02T06:59:32.817728Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Attn 3","metadata":{}},{"cell_type":"code","source":"class AttConfig2:\n    model_name = 'roberta-base'\n    pretrained_model_path = '../input/comlitrobertabasescript'\n    \n    output_hidden_states = True\n    epochs = 3\n    num_labels = 1\n    \n    device = 'cuda'\n    \n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    weight_decay = 0.01\n    head_hidden = 512\n    \n    warmup_steps = 50","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.820466Z","iopub.execute_input":"2021-08-02T06:59:32.821019Z","iopub.status.idle":"2021-08-02T06:59:32.828019Z","shell.execute_reply.started":"2021-08-02T06:59:32.820978Z","shell.execute_reply":"2021-08-02T06:59:32.827074Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, hidden_state, attention_mask):\n\n        att = torch.tanh(self.W(hidden_state))\n        score = self.V(att)\n\n        mask_expanded = attention_mask.unsqueeze(-1)\n        score[~mask_expanded] = -1e9\n\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * hidden_state\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n    \n    \nclass Mish(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return x *( torch.tanh(F.softplus(x)))\n    \n    \nclass AttModel2(nn.Module):\n    def __init__(self, config, attn_type='tradition'):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(config.pretrained_model_path)\n        self.config.update({\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": 0.0,\n                \"attention_probs_dropout_prob\": 0.1,\n                \"layer_norm_eps\": 1e-7\n                }) \n        self.roberta = AutoModel.from_pretrained(config.pretrained_model_path,\n                                                 config=self.config)\n        self.head = AttentionHead(self.config.hidden_size, config.head_hidden)\n\n        self.layer_norm = nn.LayerNorm(self.config.hidden_size, eps=1e-5)\n        self.regressor = nn.Sequential(\n                nn.Linear(self.config.hidden_size, 512),\n                Mish(),\n                nn.Linear(512, 1)\n        )\n        \n        self.dropout = nn.Dropout(p=0.1)\n        self.m_dropout = nn.Dropout(p=0.5)\n        \n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n        hidden_states = outputs[2][-1]\n\n        x = self.head(hidden_states, attention_mask)\n\n        x = self.layer_norm(x)\n        logits = self.regressor(x)\n        \n        return logits, x","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.829726Z","iopub.execute_input":"2021-08-02T06:59:32.830325Z","iopub.status.idle":"2021-08-02T06:59:32.846823Z","shell.execute_reply.started":"2021-08-02T06:59:32.830287Z","shell.execute_reply":"2021-08-02T06:59:32.845834Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Mean v2","metadata":{}},{"cell_type":"code","source":"# Mean Model\nclass MeanV2BaseConfig:\n    model_name = 'roberta-base'\n    pretrained_model_path = '../input/comlitrobertabasescript'\n    \n    epochs = 3\n    batch_size = 16\n    test_batch = 32\n    \n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    weight_decay = 0.01\n    \n    head_hidden = 512","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.848361Z","iopub.execute_input":"2021-08-02T06:59:32.848922Z","iopub.status.idle":"2021-08-02T06:59:32.857484Z","shell.execute_reply.started":"2021-08-02T06:59:32.848877Z","shell.execute_reply":"2021-08-02T06:59:32.856516Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Mean Large Model\nclass MeanV2LargeConfig:\n    model_name = 'roberta-large'\n    pretrained_model_path = '../input/comlitrobertalargescript'\n    \n    epochs = 3\n    batch_size = 16\n    test_batch = 32\n    \n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    weight_decay = 0.01\n    \n    head_hidden = 512","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.861176Z","iopub.execute_input":"2021-08-02T06:59:32.861467Z","iopub.status.idle":"2021-08-02T06:59:32.869038Z","shell.execute_reply.started":"2021-08-02T06:59:32.861434Z","shell.execute_reply":"2021-08-02T06:59:32.868119Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# V2 base :  inference model\n\nclass MeanPooling(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        \n    def forward(self, hidden_state, attention_mask):\n        # last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        \n        return mean_embeddings\n\n\n#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n#https://arxiv.org/abs/1908.08681v1\nclass Mish(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return x *( torch.tanh(F.softplus(x)))\n\n    \nclass MeanModel_v2(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(config.pretrained_model_path)\n        self.config.update({\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": 0.0,\n                \"attention_probs_dropout_prob\": 0.1,\n                \"layer_norm_eps\": 1e-7\n                }) \n        self.roberta = AutoModel.from_pretrained(config.pretrained_model_path,\n                                                 config=self.config)\n        \n        self.pooler = MeanPooling(self.config.hidden_size)\n        self.layer_norm = nn.LayerNorm(self.config.hidden_size, eps=1e-5)\n        \n        self.dropout = nn.Dropout(0.5)\n        self.regressor = nn.Sequential(\n                nn.Linear(self.config.hidden_size, 512),\n                Mish(),\n                nn.Linear(512, 1)\n        )\n        \n        self.std = 0.02\n        self._init_weights(self.regressor)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            # module.weight.data.normal_(mean=0.0, std=self.std)\n            init.kaiming_normal_(module.weight, mode='fan_in')\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n        \n        ## MeanPooling\n        hidden_states = outputs[0]\n        pool_out = self.pooler(hidden_states, attention_mask)\n        # pool_out = self.dropout(pool_out)\n        pool_out = self.layer_norm(pool_out)\n        logits = self.regressor(pool_out)\n\n        return logits, pool_out","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.872224Z","iopub.execute_input":"2021-08-02T06:59:32.872504Z","iopub.status.idle":"2021-08-02T06:59:32.891838Z","shell.execute_reply.started":"2021-08-02T06:59:32.872463Z","shell.execute_reply":"2021-08-02T06:59:32.890838Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Infer func","metadata":{}},{"cell_type":"code","source":"def get_test_data(df):\n    tokenizer = torch.load('/kaggle/input/tokenizer/roberta_tk.pt') \n    test_dataset = RoBERTaDataset(df, tokenizer, for_test=True)\n    test_loader = DataLoader(test_dataset, batch_size=32,\n                             num_workers=4, shuffle=False, pin_memory=True,\n                             drop_last=False)\n    return test_loader","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.893297Z","iopub.execute_input":"2021-08-02T06:59:32.893924Z","iopub.status.idle":"2021-08-02T06:59:32.902090Z","shell.execute_reply.started":"2021-08-02T06:59:32.893860Z","shell.execute_reply":"2021-08-02T06:59:32.901210Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def reset_memory():\n    gc.collect()\n    torch.cuda.synchronize()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.903566Z","iopub.execute_input":"2021-08-02T06:59:32.904015Z","iopub.status.idle":"2021-08-02T06:59:32.911239Z","shell.execute_reply.started":"2021-08-02T06:59:32.903940Z","shell.execute_reply":"2021-08-02T06:59:32.910385Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def inference(test_dataloader, model_dirs, model=None, n_models=5, ckpt_bias=0, with_embedding=False):\n    models_preds = []\n    models_embedding = []\n    for model_num in range(n_models):\n        print(f'{by_}{r_}  >>> Inference # {model_num+1}/{n_models}  {sr_}')\n        torch.cuda.synchronize()\n\n        # load\n        model_path = model_dirs[model_num]\n        print(f\" ### Using {model_path}\")\n        if model:\n            model.load_state_dict(torch.load(model_path, map_location=Config.device))\n        else:\n            model = torch.load(model_path)\n        model.to(Config.device)\n\n        # predict\n        fold_preds = []\n        embeddings = []\n        model.eval()\n        with torch.no_grad():\n            for step, batch in enumerate(test_dataloader):\n                sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n                preds = model(sent_id, mask)\n                \n                if with_embedding and len(preds) == 2:\n                    preds, embed = preds[0], preds[1]\n                    embed = embed.detach().cpu().numpy()\n                    embeddings.extend(embed)\n                if len(preds) == 2:\n                    preds = preds[0]\n                fold_preds += preds.flatten().cpu().tolist()\n\n        # records\n        models_preds.append(fold_preds)\n        if with_embedding:\n            models_embedding.append(np.array(embeddings))\n\n        if not model:  # load_state_dict 方式，不能在这里删除\n            del model\n            gc.collect()\n            torch.cuda.synchronize()\n            torch.cuda.empty_cache()\n\n        print(f'! Model Complete. ++++++++++')\n    print()\n\n    # output\n    models_preds = np.array(models_preds).mean(axis=0)\n    if not with_embedding:\n        return models_preds\n    else:\n        return models_preds, models_embedding","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.913083Z","iopub.execute_input":"2021-08-02T06:59:32.913390Z","iopub.status.idle":"2021-08-02T06:59:32.926831Z","shell.execute_reply.started":"2021-08-02T06:59:32.913364Z","shell.execute_reply":"2021-08-02T06:59:32.925795Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def embedding_svr_test(embeddings, num_pred, bert_nums=5, svr_nfolds=10):\n    # SVM predict: 5 SVR model\n    results = np.zeros(num_pred)\n    for index, X_test in enumerate(embeddings):\n        print(f'{by_}{r_}  SVR#{index+1} predicting {sr_}')\n        for i in range(svr_nfolds):\n            svr = load(save_dir + f'svr_{index}_{i}.bin')\n            preds = svr.predict(X_test)\n            results += preds\n    print(f'SVR Complete.')\n\n    return results / bert_nums / svr_nfolds","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.928674Z","iopub.execute_input":"2021-08-02T06:59:32.929124Z","iopub.status.idle":"2021-08-02T06:59:32.937841Z","shell.execute_reply.started":"2021-08-02T06:59:32.929084Z","shell.execute_reply":"2021-08-02T06:59:32.936886Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install textstat --no-index --find-links=file:///kaggle/input/textstat-local/textstat \n\n# import textstat\n\n# def add_textstat_features(df):\n#     ### You can add/remove any feature below and it will be used in training and test\n#     df['coleman_liau_index'] = df['excerpt'].apply(lambda x: textstat.coleman_liau_index(x))\n#     df['flesch_reading_ease'] = df['excerpt'].apply(lambda x: textstat.flesch_reading_ease(x))\n#     df['smog_index'] = df['excerpt'].apply(lambda x: textstat.smog_index(x))\n#     df['dale_chall_readability_score'] = df['excerpt'].apply(lambda x: textstat.dale_chall_readability_score(x))\n#     return df\n\n# def difficult_words_ratio(df, input_col='excerpt', output_col='difficult_words_ratio'):\n#     print(f\"Applying {output_col} to data set.\")\n#     df[output_col] = df[input_col].apply(lambda x: textstat.difficult_words(x))\n#     df[output_col] = df.apply(lambda x: x[output_col] / textstat.lexicon_count(x[input_col]), axis=1)\n#     return df \n\n# def syllable_ratio(df, input_col='excerpt', output_col='syllable_ratio'):\n#     print(f\"Applying {output_col} to data set.\")\n#     df[output_col] = df[input_col].apply(lambda x: textstat.syllable_count(x))\n#     df[output_col] = df.apply(lambda x: x[output_col] / textstat.lexicon_count(x[input_col]), axis=1)\n#     return df","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.939390Z","iopub.execute_input":"2021-08-02T06:59:32.940077Z","iopub.status.idle":"2021-08-02T06:59:32.947566Z","shell.execute_reply.started":"2021-08-02T06:59:32.940037Z","shell.execute_reply":"2021-08-02T06:59:32.946720Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def save_embeddings(embeds, path):\n    import pickle\n    with open(path, \"wb\") as f:\n        pickle.dump(embeds, f)\n\ndef load_embeddings(path):\n    import pickle\n    with open(path, \"rb\") as f:\n        emb = pickle.load(f)\n    return emb","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.949190Z","iopub.execute_input":"2021-08-02T06:59:32.949475Z","iopub.status.idle":"2021-08-02T06:59:32.956634Z","shell.execute_reply.started":"2021-08-02T06:59:32.949448Z","shell.execute_reply":"2021-08-02T06:59:32.955580Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## MAIN","metadata":{}},{"cell_type":"code","source":"# test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/cmlit-fold/train_data.csv\")\ntest_df['excerpt'] = test_df['excerpt'].apply(lambda x: x.replace('\\n',' '))\n\n\n\ntest_dataloader = get_test_data(test_df)\n#### LitModel: 467\nLit = [f'../input/comlitothers/model_{i + 1}.bin' for i in range(5)]\nlitmodel = LitModel()  # if use load_state_dict, init model\npred_litm, embed1 = inference(test_dataloader, Lit, model=litmodel, ckpt_bias=1,with_embedding=True)\ntest_df[\"m1\"] = pred_litm\nsave_embeddings(embed1, \"./embed1.bin\")\n\ndel litmodel, test_dataloader\nreset_memory()\n\n\n# #### mean large v2: 0.469  Nice\n# MeanL_3 = [ f'/kaggle/input/newmeanlarge/model_{i}.bin' for i in range(5)]\n# config = MeanV2LargeConfig()\n# meanmodel3 = MeanModel_v2(config)\n# pred_mean_v3, embed2 = inference(test_dataloader, MeanL_3, model=meanmodel3, with_embedding=True)\n# # svr_preds = embedding_svr_test(embeddings, len(test_df))\n# test_df[\"m2\"] = pred_mean_v3\n# save_embeddings(embed2, \"./embed2.bin\")\n\n# del meanmodel3\n# reset_memory()\n\n\ntest_dataloader = get_test_data(test_df)\n#### attn large 1:  0.464\nAttL_1 = [ f'/kaggle/input/largeattnlit/model_{i}.bin' for i in range(5)]\nconfig = AttConfig1()\nattmodel1 = AttModel(config)\npred_attL_v1, embed3 = inference(test_dataloader, AttL_1, model=attmodel1, with_embedding=True)\n# svr_preds = embedding_svr_test(embeddings, len(test_df))\ntest_df[\"m3\"] = pred_attL_v1\nsave_embeddings(embed3, \"./embed3.bin\")\n\ndel attmodel1, test_dataloader\nreset_memory()\n\n\n\ntest_dataloader = get_test_data(test_df)\n#### mean large v2 reinit: 0.466\nMeanL_4 = [ f'/kaggle/input/meanlargereinit/model_{i}.bin' for i in range(5)]\nconfig = MeanV2LargeConfig()\nmeanmodel4 = MeanModel_v2(config)\npred_mean_v4, embed4 = inference(test_dataloader, MeanL_4, model=meanmodel4, with_embedding=True)\n# svr_preds = embedding_svr_test(embeddings, len(test_df))\ntest_df[\"m4\"] = pred_mean_v4\nsave_embeddings(embed4, \"./embed4.bin\")\n\ndel meanmodel4, test_dataloader\nreset_memory()\n\n\n\ntest_dataloader = get_test_data(test_df)\n#### attn large reinit 2:  0.467\nAttL_2 = [ f'/kaggle/input/attlargereinit/model_{i}.bin' for i in range(5)]\nconfig = AttConfig1()\nattmodel2 = AttModel(config)\npred_attL_v2, embed2  = inference(test_dataloader, AttL_2, model=attmodel2, with_embedding=True)\n# svr_preds = embedding_svr_test(embeddings, len(test_df))\ntest_df[\"m2\"] = pred_attL_v2\nsave_embeddings(embed2, \"./embed2.bin\")\n\ndel attmodel2, test_dataloader\nreset_memory()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:59:32.960575Z","iopub.execute_input":"2021-08-02T06:59:32.960853Z","iopub.status.idle":"2021-08-02T07:25:49.841192Z","shell.execute_reply.started":"2021-08-02T06:59:32.960827Z","shell.execute_reply":"2021-08-02T07:25:49.839131Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at /kaggle/input/comlitrobertabasescript/ were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at /kaggle/input/comlitrobertabasescript/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[43m\u001b[31m  >>> Inference # 1/5  \u001b[0m\n ### Using ../input/comlitothers/model_1.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 2/5  \u001b[0m\n ### Using ../input/comlitothers/model_2.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 3/5  \u001b[0m\n ### Using ../input/comlitothers/model_3.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 4/5  \u001b[0m\n ### Using ../input/comlitothers/model_4.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 5/5  \u001b[0m\n ### Using ../input/comlitothers/model_5.bin\n! Model Complete. ++++++++++\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at ../input/comlitrobertalargescript were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at ../input/comlitrobertalargescript and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[43m\u001b[31m  >>> Inference # 1/5  \u001b[0m\n ### Using /kaggle/input/largeattnlit/model_0.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 2/5  \u001b[0m\n ### Using /kaggle/input/largeattnlit/model_1.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 3/5  \u001b[0m\n ### Using /kaggle/input/largeattnlit/model_2.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 4/5  \u001b[0m\n ### Using /kaggle/input/largeattnlit/model_3.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 5/5  \u001b[0m\n ### Using /kaggle/input/largeattnlit/model_4.bin\n! Model Complete. ++++++++++\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at ../input/comlitrobertalargescript were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at ../input/comlitrobertalargescript and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[43m\u001b[31m  >>> Inference # 1/5  \u001b[0m\n ### Using /kaggle/input/meanlargereinit/model_0.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 2/5  \u001b[0m\n ### Using /kaggle/input/meanlargereinit/model_1.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 3/5  \u001b[0m\n ### Using /kaggle/input/meanlargereinit/model_2.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 4/5  \u001b[0m\n ### Using /kaggle/input/meanlargereinit/model_3.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 5/5  \u001b[0m\n ### Using /kaggle/input/meanlargereinit/model_4.bin\n! Model Complete. ++++++++++\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at ../input/comlitrobertalargescript were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at ../input/comlitrobertalargescript and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[43m\u001b[31m  >>> Inference # 1/5  \u001b[0m\n ### Using /kaggle/input/attlargereinit/model_0.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 2/5  \u001b[0m\n ### Using /kaggle/input/attlargereinit/model_1.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 3/5  \u001b[0m\n ### Using /kaggle/input/attlargereinit/model_2.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 4/5  \u001b[0m\n ### Using /kaggle/input/attlargereinit/model_3.bin\n! Model Complete. ++++++++++\n\u001b[43m\u001b[31m  >>> Inference # 5/5  \u001b[0m\n ### Using /kaggle/input/attlargereinit/model_4.bin\n! Model Complete. ++++++++++\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# embedding\n# features = embed3\n\n# 预测值\n# text stats features\n# test_df = add_textstat_features(test_df)\n# test_df = difficult_words_ratio(test_df)\n# test_df = syllable_ratio(test_df)\n\n# print(test_df.head())\n# test_df.to_csv(\"./mldata.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:25:49.848223Z","iopub.execute_input":"2021-08-02T07:25:49.848498Z","iopub.status.idle":"2021-08-02T07:25:49.855909Z","shell.execute_reply.started":"2021-08-02T07:25:49.848471Z","shell.execute_reply":"2021-08-02T07:25:49.855157Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# import os\n\n# # !pip install kaggle\n\n# os.environ[\"KAGGLE_USERNAME\"] = \"racleray\"\n# os.environ[\"KAGGLE_KEY\"] = \"d1c80c062506c912e369893b207eaca9\"\n\n# !kaggle datasets metadata racleray/comlitmldata\n# # !mv dataset-metadata.json model/\n\n# # 最好不要有文件夹\n# !kaggle datasets version -p ./ -m \"Updated data base fine\"","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:25:49.857779Z","iopub.execute_input":"2021-08-02T07:25:49.858368Z","iopub.status.idle":"2021-08-02T07:25:49.868652Z","shell.execute_reply.started":"2021-08-02T07:25:49.858331Z","shell.execute_reply":"2021-08-02T07:25:49.867800Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### ML","metadata":{}},{"cell_type":"code","source":"embed1 = load_embeddings(\"./embed1.bin\")\nprint(len(embed1))\n\nembed2 = load_embeddings(\"./embed2.bin\")\nprint(len(embed2))\n\nembed3 = load_embeddings(\"./embed3.bin\")\nprint(len(embed3))\n\nembed4 = load_embeddings(\"./embed4.bin\")\nprint(len(embed4))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:26:04.797760Z","iopub.execute_input":"2021-08-02T07:26:04.798080Z","iopub.status.idle":"2021-08-02T07:26:04.910218Z","shell.execute_reply.started":"2021-08-02T07:26:04.798052Z","shell.execute_reply":"2021-08-02T07:26:04.909234Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"5\n5\n5\n5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"SVR","metadata":{}},{"cell_type":"code","source":"# rmse_score SVR\nfrom joblib import dump, load\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\n\ntrain_data = test_df\n\n## Reset bins\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:, 'bins'] = pd.cut(train_data['target'], bins=num_bins, labels=False)\n\ntarget = train_data['target'].to_numpy()\nbins = train_data.bins.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:26:31.229596Z","iopub.execute_input":"2021-08-02T07:26:31.229943Z","iopub.status.idle":"2021-08-02T07:26:31.262497Z","shell.execute_reply.started":"2021-08-02T07:26:31.229913Z","shell.execute_reply":"2021-08-02T07:26:31.261575Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:26:44.156364Z","iopub.execute_input":"2021-08-02T07:26:44.156737Z","iopub.status.idle":"2021-08-02T07:26:44.192233Z","shell.execute_reply.started":"2021-08-02T07:26:44.156704Z","shell.execute_reply":"2021-08-02T07:26:44.191249Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"          id                          url_legal    license  \\\n0  f305c0e4a  https://www.africanstorybook.org/  CC BY 4.0   \n1  b5b6a8c91                                NaN        NaN   \n2  9a9b134c8                                NaN        NaN   \n3  f6172c6a5                                NaN        NaN   \n4  84d86d648                                NaN        NaN   \n\n                                             excerpt    target  \\\n0  Zonke runs home. It's quite hot. Fortunately t...  0.059705   \n1  Then the causes of the war are summed up and t... -2.467364   \n2  One day mousie managed to get his door open an...  0.323143   \n3  In a system of arc lighting, however, we have ... -2.882630   \n4  The nature of incrustation and the evils resul... -2.519765   \n\n   standard_error  kfold  bins        m1        m3        m4        m2  \n0        0.470262      0     8 -0.257335 -0.118455  0.022293 -0.120040  \n1        0.511015      0     2 -2.249151 -2.206307 -2.206216 -2.287320  \n2        0.516715      0     8  0.210188  0.306258  0.274027  0.235040  \n3        0.532794      0     1 -2.568251 -2.748233 -2.770499 -2.757580  \n4        0.538096      0     2 -2.828407 -2.721420 -2.867517 -2.889204  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url_legal</th>\n      <th>license</th>\n      <th>excerpt</th>\n      <th>target</th>\n      <th>standard_error</th>\n      <th>kfold</th>\n      <th>bins</th>\n      <th>m1</th>\n      <th>m3</th>\n      <th>m4</th>\n      <th>m2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f305c0e4a</td>\n      <td>https://www.africanstorybook.org/</td>\n      <td>CC BY 4.0</td>\n      <td>Zonke runs home. It's quite hot. Fortunately t...</td>\n      <td>0.059705</td>\n      <td>0.470262</td>\n      <td>0</td>\n      <td>8</td>\n      <td>-0.257335</td>\n      <td>-0.118455</td>\n      <td>0.022293</td>\n      <td>-0.120040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b5b6a8c91</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Then the causes of the war are summed up and t...</td>\n      <td>-2.467364</td>\n      <td>0.511015</td>\n      <td>0</td>\n      <td>2</td>\n      <td>-2.249151</td>\n      <td>-2.206307</td>\n      <td>-2.206216</td>\n      <td>-2.287320</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9a9b134c8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>One day mousie managed to get his door open an...</td>\n      <td>0.323143</td>\n      <td>0.516715</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0.210188</td>\n      <td>0.306258</td>\n      <td>0.274027</td>\n      <td>0.235040</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f6172c6a5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>In a system of arc lighting, however, we have ...</td>\n      <td>-2.882630</td>\n      <td>0.532794</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-2.568251</td>\n      <td>-2.748233</td>\n      <td>-2.770499</td>\n      <td>-2.757580</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84d86d648</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The nature of incrustation and the evils resul...</td>\n      <td>-2.519765</td>\n      <td>0.538096</td>\n      <td>0</td>\n      <td>2</td>\n      <td>-2.828407</td>\n      <td>-2.721420</td>\n      <td>-2.867517</td>\n      <td>-2.889204</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\n\n# input whole train_data not shuffled\ndef embedding_svr_train(df, bins, models_embedding, save_dir=\"./\", emb=1, bert_nums=5, svr_nfolds=10, C=8, kernel='rbf'):\n    mean_scores = []\n    records = []\n\n    # get embeddings\n    #print(models_embedding[0].shape)\n    #print(type(models_embedding[0]))    \n    print(\"Embedding got.\")    \n\n    \n    # SVM training: 5 SVR model\n    for index, X in enumerate(models_embedding):\n        print(f'{by_}{r_}  SVR#{index+1} training {sr_}')\n        scores = []\n        model = SVR(C=C, kernel=kernel, gamma='auto')\n        # new kfold\n        kfold = StratifiedKFold(n_splits=svr_nfolds, shuffle=True, random_state=42)\n        for i, (train_idx, valid_idx) in tqdm(enumerate(kfold.split(X, bins))):\n#             model = SVR(C=C, kernel=kernel, gamma='auto')\n            X_train, y_train = X[train_idx], target[train_idx]\n            X_valid, y_valid = X[valid_idx], target[valid_idx]\n            \n            model.fit(X_train, y_train)\n            \n            prediction = model.predict(X_valid)\n            score = rmse_score(prediction, y_valid)\n            scores.append(score)\n            print(f'\\t\\t{y_}SVR {index} Fold {i} , rmse score: {score:.4f} {sr_}')\n\n        os.makedirs(save_dir, exist_ok=True)\n        dump(model, save_dir + f'svr_{emb}_{index}.bin')\n\n        mean_score = np.mean(scores)\n        print(f'\\t{r_}SVR {index} mean rmse score: {mean_score:.4f} {sr_}')\n        mean_scores.append(mean_score)\n        records.append(scores)\n\n    print(f'Avg rmse score of 5 SVR: {np.mean(mean_scores):.4f}')\n\n    return records","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:27:13.336278Z","iopub.execute_input":"2021-08-02T07:27:13.336674Z","iopub.status.idle":"2021-08-02T07:27:13.347955Z","shell.execute_reply.started":"2021-08-02T07:27:13.336640Z","shell.execute_reply":"2021-08-02T07:27:13.346812Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"embedding_svr_train(train_data, bins, embed1, emb=1, svr_nfolds=5, C=100) ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:27:14.853609Z","iopub.execute_input":"2021-08-02T07:27:14.853973Z","iopub.status.idle":"2021-08-02T07:29:42.928162Z","shell.execute_reply.started":"2021-08-02T07:27:14.853941Z","shell.execute_reply":"2021-08-02T07:29:42.927208Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Embedding got.\n\u001b[43m\u001b[31m  SVR#1 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:05,  5.71s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 0 , rmse score: 0.3454 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:11,  5.82s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 1 , rmse score: 0.3066 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:17,  5.88s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 2 , rmse score: 0.3377 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:23,  5.85s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 3 , rmse score: 0.3409 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:29,  5.81s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 4 , rmse score: 0.3207 \u001b[0m\n\t\u001b[31mSVR 0 mean rmse score: 0.3303 \u001b[0m\n\u001b[43m\u001b[31m  SVR#2 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:05,  5.83s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 0 , rmse score: 0.3429 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:11,  5.89s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 1 , rmse score: 0.3256 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:17,  5.86s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 2 , rmse score: 0.3443 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:23,  5.90s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 3 , rmse score: 0.3700 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:29,  5.84s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 4 , rmse score: 0.3407 \u001b[0m\n\t\u001b[31mSVR 1 mean rmse score: 0.3447 \u001b[0m\n\u001b[43m\u001b[31m  SVR#3 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:06,  6.17s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 0 , rmse score: 0.3596 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:12,  6.06s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 1 , rmse score: 0.3317 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:18,  6.01s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 2 , rmse score: 0.3437 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:23,  5.93s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 3 , rmse score: 0.3450 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:29,  5.96s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 4 , rmse score: 0.3316 \u001b[0m\n\t\u001b[31mSVR 2 mean rmse score: 0.3423 \u001b[0m\n\u001b[43m\u001b[31m  SVR#4 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:05,  5.82s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 0 , rmse score: 0.3545 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:11,  5.97s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 1 , rmse score: 0.3296 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:17,  6.02s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 2 , rmse score: 0.3433 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:24,  6.02s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 3 , rmse score: 0.3499 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:30,  6.03s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 4 , rmse score: 0.3387 \u001b[0m\n\t\u001b[31mSVR 3 mean rmse score: 0.3432 \u001b[0m\n\u001b[43m\u001b[31m  SVR#5 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:06,  6.03s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 0 , rmse score: 0.3716 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:12,  6.03s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 1 , rmse score: 0.3513 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:18,  6.00s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 2 , rmse score: 0.3606 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:23,  5.96s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 3 , rmse score: 0.3452 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:29,  5.95s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 4 , rmse score: 0.3408 \u001b[0m\n\t\u001b[31mSVR 4 mean rmse score: 0.3539 \u001b[0m\nAvg rmse score of 5 SVR: 0.3429\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[[0.34542270076541276,\n  0.3066241762632316,\n  0.3376639678954363,\n  0.34089036541837203,\n  0.3206861963784917],\n [0.34288948821891163,\n  0.3255652466470202,\n  0.3442932237216695,\n  0.36999307523492914,\n  0.3407440016154367],\n [0.35957686789556764,\n  0.3316827325149671,\n  0.34366729198538715,\n  0.3450497578191213,\n  0.33155643655330974],\n [0.35447239387690144,\n  0.32958864038603186,\n  0.34326825974642905,\n  0.34992483278055764,\n  0.338717355762261],\n [0.37158189102335165,\n  0.3512817192865013,\n  0.36063067444118924,\n  0.34515415649942255,\n  0.3407595911639054]]"},"metadata":{}}]},{"cell_type":"code","source":"embedding_svr_train(train_data, bins, embed1, svr_nfolds=5, C=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:29:42.929985Z","iopub.execute_input":"2021-08-02T07:29:42.930332Z","iopub.status.idle":"2021-08-02T07:29:42.934990Z","shell.execute_reply.started":"2021-08-02T07:29:42.930296Z","shell.execute_reply":"2021-08-02T07:29:42.934021Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"embedding_svr_train(train_data, bins, embed1, emb=1, svr_nfolds=5, C=200)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:29:42.937402Z","iopub.execute_input":"2021-08-02T07:29:42.937840Z","iopub.status.idle":"2021-08-02T07:29:42.944498Z","shell.execute_reply.started":"2021-08-02T07:29:42.937801Z","shell.execute_reply":"2021-08-02T07:29:42.943474Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"embedding_svr_train(train_data, bins, embed2, emb=2, svr_nfolds=5, C=200)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:29:42.946063Z","iopub.execute_input":"2021-08-02T07:29:42.946405Z","iopub.status.idle":"2021-08-02T07:34:09.937115Z","shell.execute_reply.started":"2021-08-02T07:29:42.946369Z","shell.execute_reply":"2021-08-02T07:34:09.936112Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Embedding got.\n\u001b[43m\u001b[31m  SVR#1 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.14s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 0 , rmse score: 0.3370 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:20, 10.53s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 1 , rmse score: 0.3422 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:31, 10.75s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 2 , rmse score: 0.3449 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:42, 10.77s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 3 , rmse score: 0.3408 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:52, 10.54s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 4 , rmse score: 0.3733 \u001b[0m\n\t\u001b[31mSVR 0 mean rmse score: 0.3476 \u001b[0m\n\u001b[43m\u001b[31m  SVR#2 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.29s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 0 , rmse score: 0.3637 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:20, 10.38s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 1 , rmse score: 0.3611 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:31, 10.73s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 2 , rmse score: 0.3608 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:42, 10.87s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 3 , rmse score: 0.3626 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:53, 10.80s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 4 , rmse score: 0.3479 \u001b[0m\n\t\u001b[31mSVR 1 mean rmse score: 0.3592 \u001b[0m\n\u001b[43m\u001b[31m  SVR#3 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.41s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 0 , rmse score: 0.3601 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:21, 10.59s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 1 , rmse score: 0.3299 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:31, 10.47s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 2 , rmse score: 0.3570 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:42, 10.52s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 3 , rmse score: 0.3475 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:53, 10.66s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 4 , rmse score: 0.3462 \u001b[0m\n\t\u001b[31mSVR 2 mean rmse score: 0.3482 \u001b[0m\n\u001b[43m\u001b[31m  SVR#4 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.76s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 0 , rmse score: 0.3519 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:21, 10.64s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 1 , rmse score: 0.3193 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:31, 10.44s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 2 , rmse score: 0.3437 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:41, 10.32s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 3 , rmse score: 0.3520 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:51, 10.39s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 4 , rmse score: 0.3281 \u001b[0m\n\t\u001b[31mSVR 3 mean rmse score: 0.3390 \u001b[0m\n\u001b[43m\u001b[31m  SVR#5 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:11, 11.04s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 0 , rmse score: 0.3640 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:22, 11.04s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 1 , rmse score: 0.3631 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:33, 11.03s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 2 , rmse score: 0.3644 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:44, 10.99s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 3 , rmse score: 0.3726 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:54, 10.99s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 4 , rmse score: 0.3485 \u001b[0m\n\t\u001b[31mSVR 4 mean rmse score: 0.3625 \u001b[0m\nAvg rmse score of 5 SVR: 0.3513\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[[0.3369784314466992,\n  0.3422228064093938,\n  0.34491332569811,\n  0.3408109833069153,\n  0.3733180779351824],\n [0.3637201404577287,\n  0.3610829405629857,\n  0.36078279780468137,\n  0.3625815295684579,\n  0.3479460353247875],\n [0.360134852736254,\n  0.3298976342619192,\n  0.3570128172001221,\n  0.34751204017336307,\n  0.3462330229028444],\n [0.3519340318365144,\n  0.3192790751929824,\n  0.3436934037302124,\n  0.35195490690301723,\n  0.32814413636124806],\n [0.3640268274635047,\n  0.36305882931730327,\n  0.3643575559389901,\n  0.3725785223150587,\n  0.34850652763179374]]"},"metadata":{}}]},{"cell_type":"code","source":"embedding_svr_train(train_data, bins, embed3, emb=3, svr_nfolds=5, C=200)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:34:09.938351Z","iopub.execute_input":"2021-08-02T07:34:09.938853Z","iopub.status.idle":"2021-08-02T07:38:15.305008Z","shell.execute_reply.started":"2021-08-02T07:34:09.938815Z","shell.execute_reply":"2021-08-02T07:38:15.303649Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Embedding got.\n\u001b[43m\u001b[31m  SVR#1 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:07,  7.97s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 0 , rmse score: 0.3009 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:15,  8.00s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 1 , rmse score: 0.2803 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:23,  7.92s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 2 , rmse score: 0.3061 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:31,  7.85s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 3 , rmse score: 0.3048 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:39,  7.83s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 4 , rmse score: 0.3331 \u001b[0m\n\t\u001b[31mSVR 0 mean rmse score: 0.3050 \u001b[0m\n\u001b[43m\u001b[31m  SVR#2 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:11, 11.07s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 0 , rmse score: 0.3783 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:22, 11.32s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 1 , rmse score: 0.3820 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:33, 11.21s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 2 , rmse score: 0.3680 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:44, 11.15s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 3 , rmse score: 0.3610 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:55, 11.05s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 4 , rmse score: 0.3540 \u001b[0m\n\t\u001b[31mSVR 1 mean rmse score: 0.3687 \u001b[0m\n\u001b[43m\u001b[31m  SVR#3 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:08,  8.80s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 0 , rmse score: 0.3283 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:18,  9.07s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 1 , rmse score: 0.3218 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:27,  9.37s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 2 , rmse score: 0.3304 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:37,  9.48s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 3 , rmse score: 0.3295 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:46,  9.29s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 4 , rmse score: 0.3141 \u001b[0m\n\t\u001b[31mSVR 2 mean rmse score: 0.3248 \u001b[0m\n\u001b[43m\u001b[31m  SVR#4 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.41s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 0 , rmse score: 0.3595 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:20, 10.25s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 1 , rmse score: 0.3384 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:30, 10.07s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 2 , rmse score: 0.3440 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:41, 10.44s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 3 , rmse score: 0.3539 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:52, 10.44s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 4 , rmse score: 0.3400 \u001b[0m\n\t\u001b[31mSVR 3 mean rmse score: 0.3472 \u001b[0m\n\u001b[43m\u001b[31m  SVR#5 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.61s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 0 , rmse score: 0.3654 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:20, 10.43s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 1 , rmse score: 0.3627 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:31, 10.35s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 2 , rmse score: 0.3752 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:41, 10.33s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 3 , rmse score: 0.3658 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:52, 10.44s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 4 , rmse score: 0.3508 \u001b[0m\n\t\u001b[31mSVR 4 mean rmse score: 0.3640 \u001b[0m\nAvg rmse score of 5 SVR: 0.3419\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[[0.3008846318301386,\n  0.2802867726295797,\n  0.3061025955906373,\n  0.30476754725983973,\n  0.3331477800721458],\n [0.3782995575127707,\n  0.38201804361946756,\n  0.3680116488543579,\n  0.36097150579246556,\n  0.35403955634611833],\n [0.3282692770367046,\n  0.3217849897624967,\n  0.3303575141942111,\n  0.32949701042460144,\n  0.31406496655708693],\n [0.35947327272156576,\n  0.33839697890060977,\n  0.344034104423757,\n  0.35387178075395104,\n  0.34001346128670284],\n [0.3653576328940215,\n  0.3627181580014248,\n  0.37521238826325043,\n  0.3658153610399832,\n  0.3507540355002089]]"},"metadata":{}}]},{"cell_type":"code","source":"embedding_svr_train(train_data, bins, embed3, svr_nfolds=5, C=250)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:38:15.307041Z","iopub.execute_input":"2021-08-02T07:38:15.307517Z","iopub.status.idle":"2021-08-02T07:38:15.313717Z","shell.execute_reply.started":"2021-08-02T07:38:15.307447Z","shell.execute_reply":"2021-08-02T07:38:15.312419Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"embedding_svr_train(train_data, bins, embed4, emb=4, svr_nfolds=5, C=200)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:38:15.315943Z","iopub.execute_input":"2021-08-02T07:38:15.316457Z","iopub.status.idle":"2021-08-02T07:42:50.069346Z","shell.execute_reply.started":"2021-08-02T07:38:15.316388Z","shell.execute_reply":"2021-08-02T07:42:50.068461Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Embedding got.\n\u001b[43m\u001b[31m  SVR#1 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:11, 11.33s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 0 , rmse score: 0.3479 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:22, 11.49s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 1 , rmse score: 0.3268 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:34, 11.38s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 2 , rmse score: 0.3263 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:45, 11.45s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 3 , rmse score: 0.3560 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:57, 11.40s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 0 Fold 4 , rmse score: 0.3559 \u001b[0m\n\t\u001b[31mSVR 0 mean rmse score: 0.3426 \u001b[0m\n\u001b[43m\u001b[31m  SVR#2 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.74s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 0 , rmse score: 0.3529 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:21, 10.52s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 1 , rmse score: 0.3354 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:31, 10.49s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 2 , rmse score: 0.3387 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:42, 10.49s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 3 , rmse score: 0.3337 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:53, 10.70s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 1 Fold 4 , rmse score: 0.3378 \u001b[0m\n\t\u001b[31mSVR 1 mean rmse score: 0.3397 \u001b[0m\n\u001b[43m\u001b[31m  SVR#3 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:11, 11.43s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 0 , rmse score: 0.3606 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:22, 10.96s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 1 , rmse score: 0.3417 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:32, 10.80s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 2 , rmse score: 0.3482 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:43, 10.65s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 3 , rmse score: 0.3410 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:53, 10.72s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 2 Fold 4 , rmse score: 0.3432 \u001b[0m\n\t\u001b[31mSVR 2 mean rmse score: 0.3469 \u001b[0m\n\u001b[43m\u001b[31m  SVR#4 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:11, 11.39s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 0 , rmse score: 0.3640 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:22, 11.24s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 1 , rmse score: 0.3375 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:33, 11.05s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 2 , rmse score: 0.3466 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:43, 10.81s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 3 , rmse score: 0.3563 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:54, 10.81s/it]\n0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 3 Fold 4 , rmse score: 0.3413 \u001b[0m\n\t\u001b[31mSVR 3 mean rmse score: 0.3491 \u001b[0m\n\u001b[43m\u001b[31m  SVR#5 training \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"1it [00:10, 10.90s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 0 , rmse score: 0.3758 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2it [00:22, 11.56s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 1 , rmse score: 0.3460 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"3it [00:34, 11.75s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 2 , rmse score: 0.3579 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"4it [00:45, 11.38s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 3 , rmse score: 0.3550 \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"5it [00:56, 11.29s/it]","output_type":"stream"},{"name":"stdout","text":"\t\t\u001b[33mSVR 4 Fold 4 , rmse score: 0.3401 \u001b[0m\n\t\u001b[31mSVR 4 mean rmse score: 0.3550 \u001b[0m\nAvg rmse score of 5 SVR: 0.3467\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"[[0.3479005349136949,\n  0.32679807654805326,\n  0.32634154275449173,\n  0.35603007301114686,\n  0.35592534787324104],\n [0.3528719546925852,\n  0.335419015287315,\n  0.3387324971504691,\n  0.3337402915881854,\n  0.33779542310578065],\n [0.36061875525910986,\n  0.3417117325496616,\n  0.34817651439157987,\n  0.34102294879441114,\n  0.3432128630570253],\n [0.3639741353603139,\n  0.33750324078849714,\n  0.34663032419664425,\n  0.3562736064353681,\n  0.34125973545973404],\n [0.37581420533554266,\n  0.34595781378819274,\n  0.3578758069246591,\n  0.35504601808971337,\n  0.34008128574996926]]"},"metadata":{}}]},{"cell_type":"code","source":"# import os\n\n# # !pip install kaggle\n\n# os.environ[\"KAGGLE_USERNAME\"] = \"\"\n# os.environ[\"KAGGLE_KEY\"] = \"\"\n\n# !kaggle datasets metadata racleray/svrmodel\n# # !mv dataset-metadata.json model/\n\n# # 最好不要有文件夹\n# !kaggle datasets version -p ./ -m \"Updated data base fine\"","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:22:13.279316Z","iopub.execute_input":"2021-08-02T08:22:13.279696Z","iopub.status.idle":"2021-08-02T08:22:13.284829Z","shell.execute_reply.started":"2021-08-02T08:22:13.279580Z","shell.execute_reply":"2021-08-02T08:22:13.283248Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Light GBM","metadata":{}},{"cell_type":"markdown","source":"过拟合","metadata":{}},{"cell_type":"code","source":"# ml_df = pd.read_csv(\"../input/comlitmldata/mldata.csv\")\n# ml_df.head()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Smaller maxbin: reduces train accuracy but has potential to increase generalization\n# Bigger min_data_in_leaf: has potential to reduce overfitting\n\n# params = {\n# 'boosting_type': 'gbdt',\n# 'objective': 'regression',\n# 'metric': 'rmse',\n#     # baseline at 100 for min_data_in_leaf\n# 'min_data_in_leaf': 100,\n#     # baseline at .8\n# 'feature_fraction': .8,\n#     # baseline at .8\n# 'bagging_fraction': 0.8,\n# 'bagging_freq': 10,\n# 'max_depth': 10,\n# 'num_leaves': 32,\n# 'learning_rate': 0.05,\n#     # baseline at max_bin 256\n# \"max_bin\": 100,\n# \"n_estimators\": 10000,\n# }\n\n\n# params = {\n#     'boosting_type': 'gbdt',\n#     'metric': 'rmse',\n#     'objective': 'regression',\n#     'verbose': -1,\n#     'learning_rate': 0.05,\n#     'max_depth': 10,\n#     'feature_pre_filter': False,\n#     'lambda_l1': 2.215942517163985,\n#     'lambda_l2': 0.0015606472088872934,\n#     'num_leaves': 2,\n#     'feature_fraction': 0.8999999999999999,\n#     'bagging_fraction': 1.0,\n#     'bagging_freq': 0,\n#     'min_child_samples': 30,\n# }\n\n\n# lgm_data = ml_df.copy()\n\n# cols2remove = ['url_legal'\n#                , 'excerpt'\n#                , 'id'\n#                , 'license'\n#                , 'kfold'\n#                , 'bins'\n#                , 'standard_error'\n# #                , 'm2', 'm3', 'm4', 'm1'\n#               ]\n\n# lgm_data = lgm_data.drop(columns=cols2remove)\n\n\n# lgm_data.head()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import lightgbm as lgm\n\n# ## Reset bins\n# num_bins = int(np.floor(1 + np.log2(len(lgm_data))))\n# lgm_data.loc[:, 'bins'] = pd.cut(lgm_data['target'], bins=num_bins, labels=False)\n\n# X = lgm_data.loc[:, lgm_data.columns != 'target'].to_numpy()\n# target = lgm_data['target'].to_numpy()\n# bins = lgm_data.bins.to_numpy()\n\n\n# pred = np.zeros(ml_df.shape[0])\n# rmses = []\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# for i, (train_idx, valid_idx) in tqdm(enumerate(kfold.split(X, bins))):\n#     X_train, y_train = X[train_idx], target[train_idx]\n#     X_valid, y_valid = X[valid_idx], target[valid_idx]\n    \n#     lgm_train_set = lgm.Dataset(data=X_train, label=y_train)\n#     lgm_valid_set = lgm.Dataset(data=X_valid, label=y_valid, reference=lgm_train_set)\n    \n#     model = lgb.train(\n#         params,\n#         lgm_train_set, \n#         num_boost_round=1000,\n#         early_stopping_rounds=10,\n#         valid_sets=[lgm_train_set, lgm_valid_set], \n#         verbose_eval=-1\n#     )\n\n#     y_pred = model.predict(X_valid)\n#     rmse = rmse_score(y_pred, y_valid)\n#     rmses.append(rmse)\n    \n#     # tmp_pred = model.predict(X_test)\n#     # pred += tmp_pred / 5\n    \n# print(\"\\n\", \"Mean Fold RMSE:\", np.mean(rmses))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n    test_df['excerpt'] = test_df['excerpt'].apply(lambda x: x.replace('\\n',' '))\n    test_dataloader = get_test_data(test_df)\n\n\n    ################### Predict ########################\n    ################## load model\n    #### Base CLRPModel \n#     CLRP_1 = [f'../input/comlitmodelone/best_model_{i}.pt' for i in range(5)]\n#     preds_c1 = inference(test_dataloader, CLRP_1, with_embedding=False)\n#     reset_memory()\n\n\n    #### Base CLRPModel \n#     CLRP_2 = [f'../input/comlitbase2/best_model_{i}.pt' for i in range(5)]\n#     preds_c2 = inference(test_dataloader, CLRP_2, with_embedding=False)\n#     reset_memory()\n\n\n\n    ################## load_state_dict\n    #### LitModel: \n#     Lit = [f'../input/comlitothers/model_{i + 1}.bin' for i in range(5)]\n#     litmodel = LitModel()  # if use load_state_dict, init model\n#     pred_lit = inference(test_dataloader, Lit, model=litmodel, ckpt_bias=1)\n#     del litmodel\n#     reset_memory()\n\n\n    #### mean large v1: 472  ;    MeanEmbedding V1 + SVM 473\n#     MeanL_1 = [ f'../input/clrobertalarger/model_{i}.bin' for i in range(5)]\n#     meanmodel = MeanModel()\n#     pred_mean_v1, embeddings = inference(test_dataloader, MeanL_1, model=meanmodel, with_embedding=True)\n#     svr_preds = embedding_svr_test(embeddings, len(test_df))\n#     del meanmodel\n#     reset_memory()\n\n\n    #### mean base v2: \n#     MeanB_2 = [ f'../input/newmeanbase/model_{i}.bin' for i in range(5)]\n#     config = MeanV2BaseConfig()\n#     meanmodel2 = MeanModel_v2(config)\n#     pred_mean_v2 = inference(test_dataloader, MeanB_2, model=meanmodel2, with_embedding=False)\n#     # svr_preds = embedding_svr_test(embeddings, len(test_df))\n#     del meanmodel2\n#     reset_memory()\n\n\n    #### mean base fgm v2: \n#     MeanBF_2 = [ f'../input/newmeanbasefgm/model_{i}.bin' for i in range(5)]\n#     config = MeanV2BaseConfig()\n#     meanmodel2f = MeanModel_v2(config)\n#     pred_mean_v2f = inference(test_dataloader, MeanBF_2, model=meanmodel2f, with_embedding=False)\n#     # svr_preds = embedding_svr_test(embeddings, len(test_df))\n#     del meanmodel2f\n#     reset_memory()\n    \n    \n    #### mean large v2: \n#     MeanL_3 = [ f'/kaggle/input/newmeanlarge/model_{i}.bin' for i in range(5)]\n#     config = MeanV2LargeConfig()\n#     meanmodel3 = MeanModel_v2(config)\n#     pred_mean_v3 = inference(test_dataloader, MeanL_3, model=meanmodel3, with_embedding=False)\n#     # svr_preds = embedding_svr_test(embeddings, len(test_df))\n#     del meanmodel3\n#     reset_memory()\n    \n\n    #### attn large 1:  \n#     AttL_1 = [ f'/kaggle/input/largeattnlit/model_{i}.bin' for i in range(5)]\n#     config = AttConfig1()\n#     attmodel1 = AttModel(config)\n#     pred_attL_v1 = inference(test_dataloader, AttL_1, model=attmodel1, with_embedding=False)\n#     # svr_preds = embedding_svr_test(embeddings, len(test_df))\n#     del attmodel1\n#     reset_memory()\n    \n    \n    #### attn base 2: \n    AttB_2 = [ f'/kaggle/input/meanattnreinit/model_{i}.bin' for i in range(5)]\n    config = AttConfig2()\n    attmodel2 = AttModel2(config)\n    pred_attL_v2 = inference(test_dataloader, AttL_2, model=attmodel2, with_embedding=False)\n    # svr_preds = embedding_svr_test(embeddings, len(test_df))\n    del attmodel2\n    reset_memory()\n    \n    # ................................................\n\n    \n    ################### Post Process ########################\n    predictions = pred_attL_v2\n#     predictions = svr_preds * 0.5 + pred_lit * 0.5  # or whatever\n\n\n    ################### Submisson ########################\n    result_df = pd.DataFrame({'id': test_df.id, 'target': predictions})\n    result_df.to_csv('submission.csv', index=False)\n    print(result_df.head(10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Only SVR inference[Test using]","metadata":{}},{"cell_type":"markdown","source":"-   id    target\n- 0  c0f722661 -0.367501\n- 1  f0953f0a5 -0.398820\n- 2  0df072751 -0.537474\n- 3  04caf4e0c -2.299636\n- 4  0e63f8bea -1.962926\n- 5  12537fe78 -1.093182\n- 6  965e592c0  0.077126","metadata":{}},{"cell_type":"markdown","source":"问题在于 需要合适的 embedding， 容易过拟合，需要bagging","metadata":{}},{"cell_type":"code","source":"# # rmse_score SVR\n# from joblib import dump, load\n# from sklearn.svm import SVR\n# from sklearn.metrics import mean_squared_error\n# from sklearn.model_selection import StratifiedKFold\n\n\n# def rmse_score(y_true,y_pred):\n#     return np.sqrt(mean_squared_error(y_true,y_pred))\n\n\n# def embedding_svr_test(df, save_dir, bert_path, bert_nums=5, svr_nfolds=10):\n#     # get embeddings\n#     models_embedding = []\n#     for fold_num in range(bert_nums):\n#         print(f'{by_}{r_}  Model#{fold_num+1} inferencing {sr_}')\n#         device = Config.device\n\n#         test_dataloader = get_test_data(df)\n\n#         model = MeanModelEmbedding()\n#         model.load_state_dict(torch.load(bert_path + f'model_{fold_num}.bin'))\n#         model.to(device)\n#         model.eval()\n\n#         embeddings = []\n#         with torch.no_grad():\n#             for i, batch in tqdm(enumerate(test_dataloader)):\n#                 sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n#                 outputs = model(sent_id, mask)\n#                 outputs = outputs.detach().cpu().numpy()\n#                 embeddings.extend(outputs)\n#             embeddings = np.array(embeddings)\n#         models_embedding.append(embeddings)\n\n#         del model\n#         gc.collect()\n#         torch.cuda.empty_cache()\n        \n#     print(f'Embedding got.')\n\n#     # SVM predict: 5 SVR model\n#     results = np.zeros((df.shape[0]))\n#     for index, X_test in enumerate(models_embedding):\n#         print(f'{by_}{r_}  SVR#{index+1} predicting {sr_}')\n#         for i in range(svr_nfolds):\n#             svr = load(save_dir + f'svr_{index}_{i}.bin')\n#             preds = svr.predict(X_test)\n#             results += preds\n            \n#     print(f'Complete.')\n\n#     return results / bert_nums / svr_nfolds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}